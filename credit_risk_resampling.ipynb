{
 "cells": [
  {
   "source": [
    "# Options"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_full_dataset = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\",\n",
    "    \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\",\n",
    "    \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\",\n",
    "    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n",
    "    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\",\n",
    "    \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"application_type\", \"acc_now_delinq\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_act_il\",\n",
    "    \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n",
    "    \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\",\n",
    "    \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\",\n",
    "    \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n",
    "    \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \"mo_sin_old_il_acct\",\n",
    "    \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\",\n",
    "    \"mths_since_recent_bc\", \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n",
    "    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\",\n",
    "    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\",\n",
    "    \"num_sats\", \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\",\n",
    "    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \"pub_rec_bankruptcies\",\n",
    "    \"tax_liens\", \"tot_hi_cred_lim\", \"total_bal_ex_mort\", \"total_bc_limit\",\n",
    "    \"total_il_high_credit_limit\", \"hardship_flag\", \"debt_settlement_flag\"\n",
    "]\n",
    "\n",
    "target = [\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "0    10500.0    0.1719       375.35           RENT     66000.0   \n",
       "1    25000.0    0.2000       929.09       MORTGAGE    105000.0   \n",
       "2    20000.0    0.2000       529.88       MORTGAGE     56000.0   \n",
       "3    10000.0    0.1640       353.55           RENT     92000.0   \n",
       "4    22000.0    0.1474       520.39       MORTGAGE     52000.0   \n",
       "\n",
       "  verification_status   issue_d loan_status pymnt_plan    dti  ...  \\\n",
       "0     Source Verified  Mar-2019    low_risk          n  27.24  ...   \n",
       "1            Verified  Mar-2019    low_risk          n  20.23  ...   \n",
       "2            Verified  Mar-2019    low_risk          n  24.26  ...   \n",
       "3            Verified  Mar-2019    low_risk          n  31.44  ...   \n",
       "4        Not Verified  Mar-2019    low_risk          n  18.76  ...   \n",
       "\n",
       "   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n",
       "0            85.7             100.0                   0.0        0.0   \n",
       "1            91.2              50.0                   1.0        0.0   \n",
       "2            66.7              50.0                   0.0        0.0   \n",
       "3           100.0              50.0                   1.0        0.0   \n",
       "4           100.0               0.0                   0.0        0.0   \n",
       "\n",
       "   tot_hi_cred_lim  total_bal_ex_mort total_bc_limit  \\\n",
       "0          65687.0            38199.0         2000.0   \n",
       "1         271427.0            60641.0        41200.0   \n",
       "2          60644.0            45684.0         7500.0   \n",
       "3          99506.0            68784.0        19700.0   \n",
       "4         219750.0            25919.0        27600.0   \n",
       "\n",
       "   total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n",
       "0                     61987.0              N                     N  \n",
       "1                     49197.0              N                     N  \n",
       "2                     43144.0              N                     N  \n",
       "3                     76506.0              N                     N  \n",
       "4                     20000.0              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>loan_status</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10500.0</td>\n      <td>0.1719</td>\n      <td>375.35</td>\n      <td>RENT</td>\n      <td>66000.0</td>\n      <td>Source Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>27.24</td>\n      <td>...</td>\n      <td>85.7</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>65687.0</td>\n      <td>38199.0</td>\n      <td>2000.0</td>\n      <td>61987.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25000.0</td>\n      <td>0.2000</td>\n      <td>929.09</td>\n      <td>MORTGAGE</td>\n      <td>105000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>20.23</td>\n      <td>...</td>\n      <td>91.2</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>271427.0</td>\n      <td>60641.0</td>\n      <td>41200.0</td>\n      <td>49197.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.0</td>\n      <td>0.2000</td>\n      <td>529.88</td>\n      <td>MORTGAGE</td>\n      <td>56000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>24.26</td>\n      <td>...</td>\n      <td>66.7</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60644.0</td>\n      <td>45684.0</td>\n      <td>7500.0</td>\n      <td>43144.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000.0</td>\n      <td>0.1640</td>\n      <td>353.55</td>\n      <td>RENT</td>\n      <td>92000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>31.44</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>99506.0</td>\n      <td>68784.0</td>\n      <td>19700.0</td>\n      <td>76506.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22000.0</td>\n      <td>0.1474</td>\n      <td>520.39</td>\n      <td>MORTGAGE</td>\n      <td>52000.0</td>\n      <td>Not Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>18.76</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>219750.0</td>\n      <td>25919.0</td>\n      <td>27600.0</td>\n      <td>20000.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('Resources/LoanStats_2019Q1.csv.zip')\n",
    "df = pd.read_csv(file_path, skiprows=1)[:-2]\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the `Issued` loan status\n",
    "issued_mask = df['loan_status'] != 'Issued'\n",
    "df = df.loc[issued_mask]\n",
    "\n",
    "# convert interest rate to numerical\n",
    "df['int_rate'] = df['int_rate'].str.replace('%', '')\n",
    "df['int_rate'] = df['int_rate'].astype('float') / 100\n",
    "\n",
    "\n",
    "# Convert the target column values to low_risk and high_risk based on their values\n",
    "x = {'Current': 'low_risk'}   \n",
    "df = df.replace(x)\n",
    "\n",
    "x = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \n",
    "df = df.replace(x)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a slice to speed up processing\n",
    "# if not process_full_dataset:\n",
    "#     df[\"loan_status\"].unique()\n",
    "#     low_risk_subset = df.copy().loc[df[\"loan_status\"] == \"low_risk\"][:100]\n",
    "#     high_risk_subset = df.copy().loc[df[\"loan_status\"] == \"high_risk\"][:100]\n",
    "#     df = low_risk_subset.append(high_risk_subset).head()\n",
    "\n",
    "df2 = df.copy()\n",
    "# df2[\"loan_status\"].unique()\n",
    "low_risk_subset = df2.loc[df2[\"loan_status\"] == \"low_risk\"][:20]\n",
    "high_risk_subset = df2.loc[df2[\"loan_status\"] == \"high_risk\"][:20]\n",
    "df = low_risk_subset.append(high_risk_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(20, 86), (20, 86), (40, 86)]"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "# df = low_risk_subset.append(high_risk_subset).head()\n",
    "[low_risk_subset.shape,\n",
    "high_risk_subset.shape,\n",
    "df.shape]\n",
    "# df\n",
    "# low_risk_subset.shape\n",
    "# high_risk_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "0    10500.0    0.1719       375.35           RENT     66000.0   \n",
       "1    25000.0    0.2000       929.09       MORTGAGE    105000.0   \n",
       "2    20000.0    0.2000       529.88       MORTGAGE     56000.0   \n",
       "3    10000.0    0.1640       353.55           RENT     92000.0   \n",
       "4    22000.0    0.1474       520.39       MORTGAGE     52000.0   \n",
       "\n",
       "  verification_status   issue_d loan_status pymnt_plan    dti  ...  \\\n",
       "0     Source Verified  Mar-2019    low_risk          n  27.24  ...   \n",
       "1            Verified  Mar-2019    low_risk          n  20.23  ...   \n",
       "2            Verified  Mar-2019    low_risk          n  24.26  ...   \n",
       "3            Verified  Mar-2019    low_risk          n  31.44  ...   \n",
       "4        Not Verified  Mar-2019    low_risk          n  18.76  ...   \n",
       "\n",
       "   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n",
       "0            85.7             100.0                   0.0        0.0   \n",
       "1            91.2              50.0                   1.0        0.0   \n",
       "2            66.7              50.0                   0.0        0.0   \n",
       "3           100.0              50.0                   1.0        0.0   \n",
       "4           100.0               0.0                   0.0        0.0   \n",
       "\n",
       "   tot_hi_cred_lim  total_bal_ex_mort total_bc_limit  \\\n",
       "0          65687.0            38199.0         2000.0   \n",
       "1         271427.0            60641.0        41200.0   \n",
       "2          60644.0            45684.0         7500.0   \n",
       "3          99506.0            68784.0        19700.0   \n",
       "4         219750.0            25919.0        27600.0   \n",
       "\n",
       "   total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n",
       "0                     61987.0              N                     N  \n",
       "1                     49197.0              N                     N  \n",
       "2                     43144.0              N                     N  \n",
       "3                     76506.0              N                     N  \n",
       "4                     20000.0              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>loan_status</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10500.0</td>\n      <td>0.1719</td>\n      <td>375.35</td>\n      <td>RENT</td>\n      <td>66000.0</td>\n      <td>Source Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>27.24</td>\n      <td>...</td>\n      <td>85.7</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>65687.0</td>\n      <td>38199.0</td>\n      <td>2000.0</td>\n      <td>61987.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25000.0</td>\n      <td>0.2000</td>\n      <td>929.09</td>\n      <td>MORTGAGE</td>\n      <td>105000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>20.23</td>\n      <td>...</td>\n      <td>91.2</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>271427.0</td>\n      <td>60641.0</td>\n      <td>41200.0</td>\n      <td>49197.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20000.0</td>\n      <td>0.2000</td>\n      <td>529.88</td>\n      <td>MORTGAGE</td>\n      <td>56000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>24.26</td>\n      <td>...</td>\n      <td>66.7</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60644.0</td>\n      <td>45684.0</td>\n      <td>7500.0</td>\n      <td>43144.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000.0</td>\n      <td>0.1640</td>\n      <td>353.55</td>\n      <td>RENT</td>\n      <td>92000.0</td>\n      <td>Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>31.44</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>99506.0</td>\n      <td>68784.0</td>\n      <td>19700.0</td>\n      <td>76506.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22000.0</td>\n      <td>0.1474</td>\n      <td>520.39</td>\n      <td>MORTGAGE</td>\n      <td>52000.0</td>\n      <td>Not Verified</td>\n      <td>Mar-2019</td>\n      <td>low_risk</td>\n      <td>n</td>\n      <td>18.76</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>219750.0</td>\n      <td>25919.0</td>\n      <td>27600.0</td>\n      <td>20000.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "low_risk_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      loan_amnt  int_rate  installment home_ownership  annual_inc  \\\n",
       "4261     4400.0    0.2000       163.52           RENT     41000.0   \n",
       "4464     5000.0    0.2880       208.99       MORTGAGE     80000.0   \n",
       "4539     5400.0    0.0819       169.70           RENT     58000.0   \n",
       "4930    11000.0    0.1474       379.92       MORTGAGE     80000.0   \n",
       "4979     1000.0    0.1797        36.14           RENT     21456.0   \n",
       "\n",
       "     verification_status   issue_d loan_status pymnt_plan    dti  ...  \\\n",
       "4261        Not Verified  Mar-2019   high_risk          n  31.82  ...   \n",
       "4464     Source Verified  Mar-2019   high_risk          n  16.88  ...   \n",
       "4539        Not Verified  Mar-2019   high_risk          n  36.50  ...   \n",
       "4930     Source Verified  Mar-2019   high_risk          n  19.82  ...   \n",
       "4979        Not Verified  Mar-2019   high_risk          n  16.72  ...   \n",
       "\n",
       "      pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n",
       "4261           100.0               0.0                   0.0        0.0   \n",
       "4464           100.0              80.0                   0.0        0.0   \n",
       "4539           100.0              20.0                   0.0        0.0   \n",
       "4930            71.4              42.9                   0.0        0.0   \n",
       "4979            94.1               0.0                   0.0        0.0   \n",
       "\n",
       "      tot_hi_cred_lim  total_bal_ex_mort total_bc_limit  \\\n",
       "4261          38014.0            27390.0         5400.0   \n",
       "4464         551300.0           113366.0        10700.0   \n",
       "4539         374414.0           476443.0        29200.0   \n",
       "4930         248484.0            52308.0        16100.0   \n",
       "4979          47375.0            19150.0        28200.0   \n",
       "\n",
       "      total_il_high_credit_limit  hardship_flag  debt_settlement_flag  \n",
       "4261                     25314.0              N                     N  \n",
       "4464                      8600.0              N                     N  \n",
       "4539                    317214.0              N                     N  \n",
       "4930                     61275.0              N                     N  \n",
       "4979                     19175.0              N                     N  \n",
       "\n",
       "[5 rows x 86 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>home_ownership</th>\n      <th>annual_inc</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>loan_status</th>\n      <th>pymnt_plan</th>\n      <th>dti</th>\n      <th>...</th>\n      <th>pct_tl_nvr_dlq</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4261</th>\n      <td>4400.0</td>\n      <td>0.2000</td>\n      <td>163.52</td>\n      <td>RENT</td>\n      <td>41000.0</td>\n      <td>Not Verified</td>\n      <td>Mar-2019</td>\n      <td>high_risk</td>\n      <td>n</td>\n      <td>31.82</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>38014.0</td>\n      <td>27390.0</td>\n      <td>5400.0</td>\n      <td>25314.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4464</th>\n      <td>5000.0</td>\n      <td>0.2880</td>\n      <td>208.99</td>\n      <td>MORTGAGE</td>\n      <td>80000.0</td>\n      <td>Source Verified</td>\n      <td>Mar-2019</td>\n      <td>high_risk</td>\n      <td>n</td>\n      <td>16.88</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>551300.0</td>\n      <td>113366.0</td>\n      <td>10700.0</td>\n      <td>8600.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4539</th>\n      <td>5400.0</td>\n      <td>0.0819</td>\n      <td>169.70</td>\n      <td>RENT</td>\n      <td>58000.0</td>\n      <td>Not Verified</td>\n      <td>Mar-2019</td>\n      <td>high_risk</td>\n      <td>n</td>\n      <td>36.50</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>374414.0</td>\n      <td>476443.0</td>\n      <td>29200.0</td>\n      <td>317214.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4930</th>\n      <td>11000.0</td>\n      <td>0.1474</td>\n      <td>379.92</td>\n      <td>MORTGAGE</td>\n      <td>80000.0</td>\n      <td>Source Verified</td>\n      <td>Mar-2019</td>\n      <td>high_risk</td>\n      <td>n</td>\n      <td>19.82</td>\n      <td>...</td>\n      <td>71.4</td>\n      <td>42.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>248484.0</td>\n      <td>52308.0</td>\n      <td>16100.0</td>\n      <td>61275.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4979</th>\n      <td>1000.0</td>\n      <td>0.1797</td>\n      <td>36.14</td>\n      <td>RENT</td>\n      <td>21456.0</td>\n      <td>Not Verified</td>\n      <td>Mar-2019</td>\n      <td>high_risk</td>\n      <td>n</td>\n      <td>16.72</td>\n      <td>...</td>\n      <td>94.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>47375.0</td>\n      <td>19150.0</td>\n      <td>28200.0</td>\n      <td>19175.0</td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "high_risk_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = df.drop(columns=\"loan_status\")\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Create our target\n",
    "y = df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          loan_amnt   int_rate  installment     annual_inc        dti  \\\n",
       "count     40.000000  40.000000    40.000000      40.000000  40.000000   \n",
       "mean   13962.500000   0.150358   425.152250   75308.300000  23.982000   \n",
       "std     7662.519084   0.049325   247.479211   52193.144939  13.097658   \n",
       "min     1000.000000   0.064600    36.140000   21456.000000   4.830000   \n",
       "25%    10000.000000   0.113650   305.840000   51828.750000  16.537500   \n",
       "50%    14000.000000   0.155700   383.760000   64147.500000  19.915000   \n",
       "75%    17175.000000   0.179700   518.657500   90000.000000  30.675000   \n",
       "max    40000.000000   0.288000  1537.990000  350000.000000  62.800000   \n",
       "\n",
       "       delinq_2yrs  inq_last_6mths   open_acc   pub_rec      revol_bal  ...  \\\n",
       "count    40.000000       40.000000  40.000000  40.00000      40.000000  ...   \n",
       "mean      0.125000        0.550000  12.450000   0.15000   17563.700000  ...   \n",
       "std       0.334932        0.749359   7.362239   0.36162   24638.649639  ...   \n",
       "min       0.000000        0.000000   4.000000   0.00000    1129.000000  ...   \n",
       "25%       0.000000        0.000000   8.000000   0.00000    6326.000000  ...   \n",
       "50%       0.000000        0.000000  10.000000   0.00000    9956.500000  ...   \n",
       "75%       0.000000        1.000000  14.250000   0.00000   18089.000000  ...   \n",
       "max       1.000000        2.000000  42.000000   1.00000  116737.000000  ...   \n",
       "\n",
       "       verification_status_Verified  issue_d_Mar-2019  pymnt_plan_n  \\\n",
       "count                     40.000000              40.0          40.0   \n",
       "mean                       0.200000               1.0           1.0   \n",
       "std                        0.405096               0.0           0.0   \n",
       "min                        0.000000               1.0           1.0   \n",
       "25%                        0.000000               1.0           1.0   \n",
       "50%                        0.000000               1.0           1.0   \n",
       "75%                        0.000000               1.0           1.0   \n",
       "max                        1.000000               1.0           1.0   \n",
       "\n",
       "       initial_list_status_f  initial_list_status_w  next_pymnt_d_May-2019  \\\n",
       "count              40.000000              40.000000                   40.0   \n",
       "mean                0.125000               0.875000                    1.0   \n",
       "std                 0.334932               0.334932                    0.0   \n",
       "min                 0.000000               0.000000                    1.0   \n",
       "25%                 0.000000               1.000000                    1.0   \n",
       "50%                 0.000000               1.000000                    1.0   \n",
       "75%                 0.000000               1.000000                    1.0   \n",
       "max                 1.000000               1.000000                    1.0   \n",
       "\n",
       "       application_type_Individual  application_type_Joint App  \\\n",
       "count                    40.000000                   40.000000   \n",
       "mean                      0.900000                    0.100000   \n",
       "std                       0.303822                    0.303822   \n",
       "min                       0.000000                    0.000000   \n",
       "25%                       1.000000                    0.000000   \n",
       "50%                       1.000000                    0.000000   \n",
       "75%                       1.000000                    0.000000   \n",
       "max                       1.000000                    1.000000   \n",
       "\n",
       "       hardship_flag_N  debt_settlement_flag_N  \n",
       "count             40.0                    40.0  \n",
       "mean               1.0                     1.0  \n",
       "std                0.0                     0.0  \n",
       "min                1.0                     1.0  \n",
       "25%                1.0                     1.0  \n",
       "50%                1.0                     1.0  \n",
       "75%                1.0                     1.0  \n",
       "max                1.0                     1.0  \n",
       "\n",
       "[8 rows x 91 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>annual_inc</th>\n      <th>dti</th>\n      <th>delinq_2yrs</th>\n      <th>inq_last_6mths</th>\n      <th>open_acc</th>\n      <th>pub_rec</th>\n      <th>revol_bal</th>\n      <th>...</th>\n      <th>verification_status_Verified</th>\n      <th>issue_d_Mar-2019</th>\n      <th>pymnt_plan_n</th>\n      <th>initial_list_status_f</th>\n      <th>initial_list_status_w</th>\n      <th>next_pymnt_d_May-2019</th>\n      <th>application_type_Individual</th>\n      <th>application_type_Joint App</th>\n      <th>hardship_flag_N</th>\n      <th>debt_settlement_flag_N</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.00000</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>40.000000</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.0</td>\n      <td>40.000000</td>\n      <td>40.000000</td>\n      <td>40.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>13962.500000</td>\n      <td>0.150358</td>\n      <td>425.152250</td>\n      <td>75308.300000</td>\n      <td>23.982000</td>\n      <td>0.125000</td>\n      <td>0.550000</td>\n      <td>12.450000</td>\n      <td>0.15000</td>\n      <td>17563.700000</td>\n      <td>...</td>\n      <td>0.200000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.125000</td>\n      <td>0.875000</td>\n      <td>1.0</td>\n      <td>0.900000</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7662.519084</td>\n      <td>0.049325</td>\n      <td>247.479211</td>\n      <td>52193.144939</td>\n      <td>13.097658</td>\n      <td>0.334932</td>\n      <td>0.749359</td>\n      <td>7.362239</td>\n      <td>0.36162</td>\n      <td>24638.649639</td>\n      <td>...</td>\n      <td>0.405096</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.334932</td>\n      <td>0.334932</td>\n      <td>0.0</td>\n      <td>0.303822</td>\n      <td>0.303822</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1000.000000</td>\n      <td>0.064600</td>\n      <td>36.140000</td>\n      <td>21456.000000</td>\n      <td>4.830000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>0.00000</td>\n      <td>1129.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>10000.000000</td>\n      <td>0.113650</td>\n      <td>305.840000</td>\n      <td>51828.750000</td>\n      <td>16.537500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>0.00000</td>\n      <td>6326.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>14000.000000</td>\n      <td>0.155700</td>\n      <td>383.760000</td>\n      <td>64147.500000</td>\n      <td>19.915000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n      <td>0.00000</td>\n      <td>9956.500000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>17175.000000</td>\n      <td>0.179700</td>\n      <td>518.657500</td>\n      <td>90000.000000</td>\n      <td>30.675000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>14.250000</td>\n      <td>0.00000</td>\n      <td>18089.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>40000.000000</td>\n      <td>0.288000</td>\n      <td>1537.990000</td>\n      <td>350000.000000</td>\n      <td>62.800000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>42.000000</td>\n      <td>1.00000</td>\n      <td>116737.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 91 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "high_risk    20\n",
       "low_risk     20\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.reset_index()['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(30, 91)"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# Create X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   random_state=1)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Scale the training and testing data using the `StandardScaler` from `sklearn`. Remember that when scaling the data, you only scale the features data (`X_train` and `X_testing`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "X_scalar = scaler.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "X_train_scaled = X_scalar.transform(X_train)\n",
    "X_test_scaled = X_scalar.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling\n",
    "\n",
    "In this section, you will compare two oversampling algorithms to determine which algorithm results in the best performance. You will oversample the data using the naive random oversampling algorithm and the SMOTE algorithm. For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'high_risk': 17, 'low_risk': 17})"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [0, 3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       1.00      0.71      1.00      0.83      0.85      0.69         7\n   low_risk       0.60      1.00      0.71      0.75      0.85      0.73         3\n\navg / total       0.88      0.80      0.91      0.81      0.85      0.71        10\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Precision (pre), Recall (rec), Accuracy (f1), Geometric (geo)\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'high_risk': 17, 'low_risk': 17})"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy=1.0).fit_resample(\n",
    "    X_train_scaled, y_train\n",
    ")\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [0, 3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       1.00      0.71      1.00      0.83      0.85      0.69         7\n   low_risk       0.60      1.00      0.71      0.75      0.85      0.73         3\n\navg / total       0.88      0.80      0.91      0.81      0.85      0.71        10\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling\n",
    "\n",
    "In this section, you will test an undersampling algorithms to determine which algorithm results in the best performance compared to the oversampling algorithms above. You will undersample the data using the Cluster Centroids algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'high_risk': 13, 'low_risk': 13})"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=1, sampling_strategy=1.0)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [0, 3]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       1.00      0.71      1.00      0.83      0.85      0.69         7\n   low_risk       0.60      1.00      0.71      0.75      0.85      0.73         3\n\navg / total       0.88      0.80      0.91      0.81      0.85      0.71        10\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination (Over and Under) Sampling\n",
    "\n",
    "In this section, you will test a combination over- and under-sampling algorithm to determine if the algorithm results in the best performance compared to the other sampling algorithms above. You will resample the data using the SMOTEENN algorithm and complete the folliowing steps:\n",
    "\n",
    "1. View the count of the target classes using `Counter` from the collections library. \n",
    "3. Use the resampled data to train a logistic regression model.\n",
    "3. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "4. Print the confusion matrix from sklearn.metrics.\n",
    "5. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "\n",
    "Note: Use a random state of 1 for each sampling algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'high_risk': 6, 'low_risk': 3})"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[7, 0],\n",
       "       [2, 1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\n  high_risk       0.78      1.00      0.33      0.88      0.58      0.36         7\n   low_risk       1.00      0.33      1.00      0.50      0.58      0.31         3\n\navg / total       0.84      0.80      0.53      0.76      0.58      0.34        10\n\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvizenv",
   "language": "python",
   "name": "pyvizenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}